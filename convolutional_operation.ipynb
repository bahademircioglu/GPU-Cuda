{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eG0sjkqJKsTX"
      },
      "outputs": [],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# CUDA kodu, block-shared memory tanımı vs\n",
        "cuda_code = \"\"\"\n",
        "__global__ void convolutionalLayerKernelWithSharedMemory(float *input, float *output, float *filter, int width, int height, int filterWidth, int filterHeight) {\n",
        "    extern __shared__ float sharedMem[];\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int row_o = blockIdx.y * blockDim.y + ty; // Output row indexi\n",
        "    int col_o = blockIdx.x * blockDim.x + tx; // Output column indexi\n",
        "    int row_i = row_o - filterHeight / 2;     // Thread için input row indexi\n",
        "    int col_i = col_o - filterWidth / 2;      // Thread için input column indexi\n",
        "    int sharedMemIndex = ty * blockDim.x + tx;\n",
        "\n",
        "    // inputu shared memorye yükleme\n",
        "    if (row_i >= 0 && row_i < height && col_i >= 0 && col_i < width) {\n",
        "        sharedMem[sharedMemIndex] = input[row_i * width + col_i];\n",
        "    } else {\n",
        "        sharedMem[sharedMemIndex] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Filtrenin uygulanması\n",
        "    if (ty < blockDim.y - filterHeight + 1 && tx < blockDim.x - filterWidth + 1) {\n",
        "        float sum = 0;\n",
        "        for (int i = 0; i < filterHeight; ++i) {\n",
        "            for (int j = 0; j < filterWidth; ++j) {\n",
        "                sum += sharedMem[(ty + i) * blockDim.x + tx + j] * filter[i * filterWidth + j];\n",
        "            }\n",
        "        }\n",
        "        if (row_o < height - filterHeight + 1 && col_o < width - filterWidth + 1) {\n",
        "            output[row_o * (width - filterWidth + 1) + col_o] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "mod = SourceModule(cuda_code)\n",
        "\n",
        "# CUDA kernel referansı (çağrılması)\n",
        "convolution_with_shared_memory = mod.get_function(\"convolutionalLayerKernelWithSharedMemory\")\n",
        "\n",
        "\n",
        "# GPU CNN işlemleri\n",
        "def forward_pass(input_data, filter_data):\n",
        "    input_height, input_width = input_data.shape\n",
        "    filter_height, filter_width = filter_data.shape\n",
        "    output_height, output_width = input_height - filter_height + 1, input_width - filter_width + 1\n",
        "\n",
        "    input_data_gpu = cuda.mem_alloc(input_data.nbytes)\n",
        "    filter_gpu = cuda.mem_alloc(filter_data.nbytes)\n",
        "    output_data_gpu = cuda.mem_alloc(output_height * output_width * input_data.itemsize)\n",
        "\n",
        "    cuda.memcpy_htod(input_data_gpu, input_data)\n",
        "    cuda.memcpy_htod(filter_gpu, filter_data)\n",
        "\n",
        "    block_size = (16, 16, 1)\n",
        "    grid_size = (int(np.ceil(output_width / 16)), int(np.ceil(output_height / 16)))\n",
        "\n",
        "    convolution(input_data_gpu, output_data_gpu, filter_gpu, np.int32(input_width), np.int32(input_height), np.int32(filter_width), np.int32(filter_height), block=block_size, grid=grid_size)\n",
        "\n",
        "    output_data = np.empty((output_height, output_width), dtype=np.float32)\n",
        "    cuda.memcpy_dtoh(output_data, output_data_gpu)\n",
        "\n",
        "    return output_data\n",
        "\n",
        "# CPU CNN işlemleri\n",
        "def convolution_cpu(input_data, filter_data):\n",
        "    input_height, input_width = input_data.shape\n",
        "    filter_height, filter_width = filter_data.shape\n",
        "    output_height, output_width = input_height - filter_height + 1, input_width - filter_width + 1\n",
        "\n",
        "    output_data = np.zeros((output_height, output_width))\n",
        "\n",
        "    for i in range(output_height):\n",
        "        for j in range(output_width):\n",
        "            output_data[i, j] = np.sum(input_data[i:i+filter_height, j:j+filter_width] * filter_data)\n",
        "\n",
        "    return output_data\n",
        "\n",
        "# Performans kontrolü\n",
        "def measure_performance(input_data, filter_data):\n",
        "    start_time = time.time()\n",
        "    output_cpu = convolution_cpu(input_data, filter_data)\n",
        "    cpu_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    output_gpu = forward_pass(input_data, filter_data)\n",
        "    gpu_time = time.time() - start_time\n",
        "\n",
        "    return cpu_time, gpu_time\n",
        "\n",
        "# Farklı matrix (görsel) ve filtre büyüklükleri tanımı\n",
        "sizes = [(256, 256), (512, 512), (1024, 1024)]\n",
        "filter_sizes = [(3, 3), (5, 5), (7, 7)]\n",
        "\n",
        "# Hepsi için hesaplama ve ölçümlerin yapılması\n",
        "for size in sizes:\n",
        "    for filter_size in filter_sizes:\n",
        "        input_data = np.random.rand(*size).astype(np.float32)\n",
        "        filter_data = np.random.rand(*filter_size).astype(np.float32)\n",
        "\n",
        "        cpu_time, gpu_time = measure_performance(input_data, filter_data)\n",
        "        print(f\"Input Size: {size}, Filter Size: {filter_size}, CPU Time: {cpu_time:.4f} s, GPU Time: {gpu_time:.4f} s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGkowudPLJzn",
        "outputId": "175a0332-6ea4-4afd-e0ee-d3a3b1f0c46e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Size: (256, 256), Filter Size: (3, 3), CPU Time: 0.3968 s, GPU Time: 0.0013 s\n",
            "Input Size: (256, 256), Filter Size: (5, 5), CPU Time: 0.4007 s, GPU Time: 0.0008 s\n",
            "Input Size: (256, 256), Filter Size: (7, 7), CPU Time: 0.3707 s, GPU Time: 0.0008 s\n",
            "Input Size: (512, 512), Filter Size: (3, 3), CPU Time: 1.5598 s, GPU Time: 0.0020 s\n",
            "Input Size: (512, 512), Filter Size: (5, 5), CPU Time: 2.1167 s, GPU Time: 0.0015 s\n",
            "Input Size: (512, 512), Filter Size: (7, 7), CPU Time: 2.2184 s, GPU Time: 0.0014 s\n",
            "Input Size: (1024, 1024), Filter Size: (3, 3), CPU Time: 6.1974 s, GPU Time: 0.0062 s\n",
            "Input Size: (1024, 1024), Filter Size: (5, 5), CPU Time: 7.4688 s, GPU Time: 0.0035 s\n",
            "Input Size: (1024, 1024), Filter Size: (7, 7), CPU Time: 6.1675 s, GPU Time: 0.0036 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UbDm2HfLO2e_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
